{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aouz6diTyyKZ",
        "outputId": "8964b787-32cb-4315-d301-b15e9b421148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-NzdBjOc6iZg"
      },
      "outputs": [],
      "source": [
        "# !pip install botorch\n",
        "# !pip install autograd-minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wrNrDMyJ79JB"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/rfeinman/pytorch-minimize.git\n",
        "# %cd pytorch-minimize\n",
        "# !pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xOFsinuKKXkg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hEo-mC2XCHIZ"
      },
      "outputs": [],
      "source": [
        "#####################################################\n",
        "### FUNCTIONS FOR PLOTTING/VISUALIZING TRAJECTORY ###\n",
        "#####################################################\n",
        "\n",
        "def rotate(x, y, angle):\n",
        "    return [x * np.cos(np.radians(angle)) - y * np.sin(np.radians(angle)), \n",
        "            x * np.sin(np.radians(angle)) + y * np.cos(np.radians(angle))]\n",
        "\n",
        "\n",
        "def plot_map(roadMap, centerLine, xlim=None, ylim=None):\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    if xlim or ylim:\n",
        "        plt.autoscale(False)\n",
        "        if xlim:\n",
        "            plt.xlim(xlim)\n",
        "        if ylim:\n",
        "            plt.ylim(ylim)\n",
        "    \n",
        "    label = True\n",
        "    for road in roadMap[1:-1]:\n",
        "        if label:\n",
        "            plt.plot(*zip(*road), color='gold', linestyle='--', label='lane line')\n",
        "            label = False\n",
        "        else:\n",
        "            plt.plot(*zip(*road), color='gold', linestyle='--')\n",
        "    \n",
        "    plt.plot(*zip(*roadMap[0]), color='black')\n",
        "    plt.plot(*zip(*roadMap[-1]), color='black', label='boundary line')\n",
        "    \n",
        "    plt.plot(*zip(*centerLine), color='red', label='centerline')\n",
        "\n",
        "    plt.plot(0, 0, 'bo', markersize=5, label='ego')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_trajectory(states, \n",
        "                    roadMap, \n",
        "                    centerLine, \n",
        "                    objects, \n",
        "                    savefig=None,\n",
        "                    xlim=None, \n",
        "                    ylim=None, \n",
        "                    verbose=False):\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    if xlim or ylim:\n",
        "        plt.autoscale(False)\n",
        "        if xlim:\n",
        "            plt.xlim(xlim)\n",
        "        if ylim:\n",
        "            plt.ylim(ylim)\n",
        "\n",
        "    for i, road in enumerate(roadMap[1:-1]):\n",
        "        if i == 0:\n",
        "            plt.plot(*zip(*road), color='gold', linestyle='--', label='lane line')\n",
        "        else:\n",
        "            plt.plot(*zip(*road), color='gold', linestyle='--')\n",
        "    \n",
        "    plt.plot(*zip(*roadMap[0]), color='black', label='boundary line')\n",
        "    plt.plot(*zip(*roadMap[-1]), color='black')\n",
        "    \n",
        "    plt.plot(*zip(*centerLine), color='red', label='centerline')\n",
        "\n",
        "    label = True\n",
        "    for obj in objects:\n",
        "        x, y = obj\n",
        "        if x != 0 or y != 0:\n",
        "            if label:\n",
        "                plt.plot(x, y, 'ro', markersize=5, label='obstacles')\n",
        "                label = False\n",
        "            else:\n",
        "                plt.plot(x, y, 'ro', markersize=5)\n",
        "\n",
        "    colors = cm.rainbow(np.linspace(0, 1, len(states)))\n",
        "    for i, state in enumerate(states):\n",
        "        x, y, velocity, heading = state\n",
        "        heading = heading % 360 \n",
        "        if verbose:\n",
        "            print(f\"x: {x}, y: {y}, velocity: {velocity}, heading: {heading}\")\n",
        "            print(f\"centerline error: {shortestDistanceToPolylineNumpy(np.array([x, y]), centerLine)}\")\n",
        "        # plot triangles\n",
        "        plt.plot(x, y, marker=(3, 0, heading - 90), markersize=7, color=colors[i])\n",
        "    print('\\n' * 2)\n",
        "\n",
        "    plt.legend()\n",
        "\n",
        "    if savefig:\n",
        "        plt.savefig(savefig)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NTNm7tT6k79G"
      },
      "outputs": [],
      "source": [
        "############################################################\n",
        "### NUMPY OPERATIONS FOR EVALUATING AND PLOTTING OUTPUTS ###\n",
        "############################################################\n",
        "\n",
        "def shortestDistanceToPolylineNumpy(pt, centerLinePts):\n",
        "\n",
        "    distance = float('inf')\n",
        "\n",
        "    for i in range(1, len(centerLinePts)):\n",
        "        ptA, ptB = centerLinePts[i - 1], centerLinePts[i]\n",
        "        # see here: http://www.math.lsa.umich.edu/~glarose/classes/calcIII/web/13_5/\n",
        "        # shift points to origin (offset by ptA)\n",
        "        ptShift = pt - ptA\n",
        "        centerLine = ptB - ptA\n",
        "\n",
        "        projection = (centerLine[0] * ptShift[0] + centerLine[1] * ptShift[1]) / np.linalg.norm(centerLine, ord=2)\n",
        "        projection = projection * centerLine + ptA\n",
        "\n",
        "        rejection_dist = np.sqrt(np.square(pt[0] - projection[0]) + np.square(pt[1] - projection[1]))\n",
        "        distance = np.minimum(rejection_dist, distance)\n",
        "\n",
        "    return distance\n",
        "\n",
        "\n",
        "def stateUpdateEqnNumpy(state, controls, timeStep):\n",
        "    controls[0, 0] = state[2, 0] * np.cos(np.deg2rad(state[3, 0]))\n",
        "    controls[1, 0] = state[2, 0] * np.sin(np.deg2rad(state[3, 0]))\n",
        "    return state + timeStep * controls\n",
        "\n",
        "\n",
        "def getUpdatedStates(initialState, controls, timeStep=1):\n",
        "    state = initialState[0][:-1]\n",
        "    states = [state]\n",
        "    for control in controls[0]:\n",
        "        paddedControls = np.concatenate((np.zeros((2, 1)), control))\n",
        "        state = stateUpdateEqnNumpy(state, constraints @ paddedControls, timeStep)\n",
        "        states.append(state)\n",
        "    return states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd5YaZSewW2g"
      },
      "source": [
        "Input a number of things:\n",
        "\n",
        "1. k nearest objects to us, with predictions of locations in near future\n",
        "2. Road-map, center-lines, etc. (polylines as features)\n",
        "3. Desired waypoint destination (x, y features) given by another larger coarse network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MtpaJldxtxiy"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "### MODEL ARCHITECTURE ###\n",
        "##########################\n",
        "\n",
        "# Concatenater of all embedding networks\n",
        "class PathPlanner(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_size,\n",
        "                 hidden_size, \n",
        "                 n_features,\n",
        "                 y_features, \n",
        "                 k_neighbors,\n",
        "                 num_layers, \n",
        "                 road_samples,\n",
        "                 gpu=0):\n",
        "        super(PathPlanner, self).__init__()\n",
        "\n",
        "        self.gpu = gpu\n",
        "\n",
        "        road_samples, road_embedding = road_samples\n",
        "        # path planner feature dimension\n",
        "        input_size = n_features + road_samples // road_embedding * 3 + k_neighbors \n",
        "\n",
        "        self.env_embed = EnvironmentMapper()\n",
        "        self.road_embed = RoadMapper(road_samples, road_embedding)\n",
        "        self.planner = MotionPlanner(input_size, hidden_size, output_size, num_layers, y_features)\n",
        "\n",
        "\n",
        "    def forward(self, x, roadmap, environment):\n",
        "        env_embedded = self.env_embed(environment)\n",
        "        map_embedded = self.road_embed(roadmap)\n",
        "        \n",
        "        x = torch.cat((x, map_embedded, env_embedded), axis=-1)\n",
        "        y = self.planner(x)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "# Motion planning network (RNN)\n",
        "class MotionPlanner(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 num_steps,\n",
        "                 num_layers,\n",
        "                 y_features):\n",
        "        super(MotionPlanner, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = num_steps\n",
        "\n",
        "        self.features_embed = nn.Linear(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, \n",
        "                          hidden_size, \n",
        "                          num_layers, \n",
        "                          batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_size, y_features)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.features_embed(x)\n",
        "        x = nn.Tanh()(x)\n",
        "\n",
        "        # Set initial hidden and cell states\n",
        "        # h_n = torch.randn(self.num_layers, batch_size, self.hidden_size, dtype=torch.double)\n",
        "        # h_n = torch.zeros(self.num_layers, batch_size, self.hidden_size, dtype=torch.double)\n",
        "        h_n = torch.ones(self.num_layers, batch_size, self.hidden_size, dtype=torch.double)\n",
        "\n",
        "        y = torch.zeros(batch_size, self.output_size, self.hidden_size, dtype=torch.double)\n",
        "        for i in range(self.output_size):\n",
        "            output_n, h_n = self.rnn(x, h_n)\n",
        "            # x, h_n = self.rnn(x, h_n)\n",
        "            y[:,i,:] = output_n\n",
        "        \n",
        "        y = self.fc1(y)\n",
        "        y = nn.Tanh()(y)\n",
        "        y = torch.unsqueeze(y, axis=-1)\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "# Road embedder (FCNN)\n",
        "class RoadMapper(nn.Module):\n",
        "    def __init__(self, samples, embedding):\n",
        "        super(RoadMapper, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 1)\n",
        "        self.fc2 = nn.Linear(samples, samples // embedding)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = nn.Tanh()(x)\n",
        "        x = torch.squeeze(x, axis=-1)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = nn.Tanh()(x)\n",
        "\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = torch.unsqueeze(x, dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Obstacle embedder (FCNN)\n",
        "class EnvironmentMapper(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EnvironmentMapper, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = nn.Tanh()(x)\n",
        "\n",
        "        x = torch.swapaxes(x, -1, -2)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Dvt-59e9yfIb"
      },
      "outputs": [],
      "source": [
        "# Use straight line and put vehicles in the center of the line\n",
        "\n",
        "# TODO: Put unused object positions at the origin and do not account for them in the loss function !!!!!\n",
        "\n",
        "# validate avoidance\n",
        "def validate_avoidance(traj, objects):\n",
        "    min_dist = float('inf')\n",
        "    for pt in traj[1:]:\n",
        "        x, y, _, _ = pt\n",
        "        for obj in objects:\n",
        "            obj_x, obj_y = obj\n",
        "            dist = math.sqrt((x - obj_x) ** 2 + (y - obj_y) ** 2)\n",
        "            min_dist = min(dist, min_dist)\n",
        "    return min_dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "TAeTe1w128Ie",
        "outputId": "de00bcf3-d517-4df0-a0b4-4cc5297b6400"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "##################################\n",
        "### DATASET BUILDING FUNCTIONS ###\n",
        "##################################\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ControlsDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[0])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[0][idx], self.data[1][idx]\n",
        "\n",
        "\n",
        "def buildDataset(n, desired_v, init_velocity=None, init_heading=None, n_objects=100):\n",
        "    positionalData = []\n",
        "    environmentalData = []\n",
        "\n",
        "    for _ in range(n):\n",
        "        v, h = 0, 0\n",
        "        if init_velocity is not None:\n",
        "            v = init_velocity\n",
        "        if init_heading is not None:\n",
        "            h = init_heading\n",
        "\n",
        "        positionalData.append([[v, h, desired_v]])\n",
        "\n",
        "        object_positions = []\n",
        "        # k = np.random.randint(1, n_objects + 1)\n",
        "        k = 30\n",
        "        x, y = 60, -7\n",
        "        for _ in range(k):\n",
        "            object_positions.append([x, y])\n",
        "            y += .5\n",
        "        \n",
        "        for _ in range(n_objects - k):\n",
        "            object_positions.append([0, 0])\n",
        "\n",
        "        environmentalData.append(object_positions)\n",
        "    \n",
        "    return np.array(positionalData), np.array(environmentalData)\n",
        "\n",
        "\n",
        "#########################################\n",
        "### CREATE ROAD LINES POLYLINE POINTS ###\n",
        "#########################################\n",
        "\n",
        "\n",
        "slope_fn = lambda pt1, pt2: [pt2[0] - pt1[0], pt2[1] - pt1[1]]\n",
        "\n",
        "def create_parallel_polyline(polyline, slopes, width, lane_no):\n",
        "    shift = lane_no * width\n",
        "    parallel_polyline = [np.array([polyline[0,0], polyline[0,1] - shift])]\n",
        "    for slope in slopes:\n",
        "        parallel_polyline.append(parallel_polyline[-1] + slope)\n",
        "    return parallel_polyline\n",
        "\n",
        "\n",
        "def create_generalized_scenario(func, \n",
        "                                domain, \n",
        "                                lane_width, \n",
        "                                n_lanes, \n",
        "                                centerline_no,\n",
        "                                n_samples=200):\n",
        "    \n",
        "    domain = np.linspace(domain[0], domain[1], n_samples)\n",
        "    left = np.array([[x, func(x)] for x in domain])\n",
        "    slopes = np.array([slope_fn(left[i-1], left[i]) for i in range(1, len(left))])\n",
        "    road_map = [left]\n",
        "    for n in range(n_lanes):\n",
        "        road_map.append(create_parallel_polyline(left, slopes, lane_width, n+1))\n",
        "    centerline = create_parallel_polyline(left, slopes, lane_width, centerline_no+0.5)\n",
        "    road_map = np.array(road_map)\n",
        "\n",
        "    return road_map, centerline\n",
        "\n",
        "\n",
        "def shift_coordinate_frame(roadMap, centerlane, egoPos):\n",
        "    egoPos = np.array([egoPos[0], egoPos[1]])\n",
        "    shiftedRoadMap = []\n",
        "    for lane in roadMap:\n",
        "        shiftedRoadMap.append(lane - egoPos)\n",
        "    shiftedRoadMap = np.array(shiftedRoadMap)    \n",
        "    centerlane = centerlane - egoPos\n",
        "    return shiftedRoadMap, centerlane\n",
        "\n",
        "\n",
        "road3_formula = lambda x: math.exp(x / 20) + 1\n",
        "road3, road3_cl = create_generalized_scenario(road3_formula,\n",
        "                                              domain=(-10, 50),\n",
        "                                              lane_width=4, \n",
        "                                              n_lanes=1,\n",
        "                                              centerline_no=0,\n",
        "                                              n_samples=500)\n",
        "road3, road3_cl = shift_coordinate_frame(road3, road3_cl, (0, 0.5))\n",
        "\n",
        "\n",
        "road1_formula = lambda x: 1/10 * x + 0\n",
        "road1, road1_cl = create_generalized_scenario(road1_formula, \n",
        "                                              domain=(-30, 100), \n",
        "                                              lane_width=4, \n",
        "                                              n_lanes=2,\n",
        "                                              centerline_no=1,\n",
        "                                              n_samples=500)\n",
        "road1, road1_cl = shift_coordinate_frame(road1, road1_cl, (0, -2.5))\n",
        "\n",
        "\n",
        "road2_formula = lambda x: 10 * math.log(x + 10) - 30\n",
        "road2, road2_cl = create_generalized_scenario(road2_formula, \n",
        "                                              domain=(-5, 150),\n",
        "                                              lane_width=4,\n",
        "                                              n_lanes=3,\n",
        "                                              centerline_no=2,\n",
        "                                              n_samples=500)\n",
        "road2, road2_cl = shift_coordinate_frame(road2, road2_cl, (-3, -13))\n",
        "\n",
        "\n",
        "road4_formula = lambda x: 0\n",
        "road4, road4_cl = create_generalized_scenario(road4_formula, \n",
        "                                              domain=(-30, 150),\n",
        "                                              lane_width=4,\n",
        "                                              n_lanes=3,\n",
        "                                              centerline_no=0,\n",
        "                                              n_samples=500)\n",
        "# road4, road4_cl = shift_coordinate_frame(road4, road4_cl, (0, -6))\n",
        "road4, road4_cl = shift_coordinate_frame(road4, road4_cl, (0, -10))\n",
        "\n",
        "\n",
        "road5_formula = lambda x: 0\n",
        "road5, road5_cl = create_generalized_scenario(road5_formula, \n",
        "                                              domain=(-30, 180),\n",
        "                                              lane_width=4,\n",
        "                                              n_lanes=1,\n",
        "                                              centerline_no=0,\n",
        "                                              n_samples=500)\n",
        "road5, road5_cl = shift_coordinate_frame(road5, road5_cl, (0, -2))\n",
        "\n",
        "\n",
        "\n",
        "road6_formula = lambda x: -math.log(x + 1)\n",
        "road6, road6_cl = create_generalized_scenario(road6_formula,\n",
        "                                              domain=(0, 160),\n",
        "                                              lane_width=4, \n",
        "                                              n_lanes=2,\n",
        "                                              centerline_no=1,\n",
        "                                              n_samples=500)\n",
        "road6, road6_cl = shift_coordinate_frame(road6, road6_cl, (2, -4.4))\n",
        "\n",
        "plot_map(road5, road5_cl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8fKl9_EemEjG"
      },
      "outputs": [],
      "source": [
        "#################################\n",
        "### LOSS FUNCTION COMPUTATION ###\n",
        "#################################\n",
        "\n",
        "\n",
        "# state: [[x1, y1, v1, h1], [x2, y2, v2, h2], ...]\n",
        "# controls: [vx, vy, a, w]\n",
        "def stateUpdateEqn(state, controls, timeStep):\n",
        "    controls[0, 0] = state[2, 0] * torch.cos(torch.deg2rad(state[3, 0]))\n",
        "    controls[1, 0] = state[2, 0] * torch.sin(torch.deg2rad(state[3, 0]))\n",
        "    return state + timeStep * controls\n",
        "\n",
        "\n",
        "def shortestDistanceToPolyline(pt, centerLinePts, discretization=3):\n",
        "\n",
        "    distance = torch.tensor(float('inf'))\n",
        "    tangentLine = None \n",
        "    # iterate over polyline points\n",
        "    for i in range(discretization, len(centerLinePts), discretization):\n",
        "        ptA, ptB = centerLinePts[i - discretization], centerLinePts[i]\n",
        "        centerLine = ptB - ptA\n",
        "\n",
        "        # # find midpoint between two sequential points\n",
        "        midPt = (ptA + ptB) / 2\n",
        "        projection = midPt\n",
        "        \n",
        "        # computer rejection distance (project position onto line and take distance)\n",
        "        # projection = (centerLine[0] * ptShift[0] + centerLine[1] * ptShift[1]) / torch.norm(centerLine, p=2)\n",
        "        # projection = projection * centerLine + ptA\n",
        "\n",
        "        # compute distance between position and mid-point, take the minimum across all\n",
        "        rejection_dist = torch.sqrt(torch.square(pt[0] - projection[0]) + torch.square(pt[1] - projection[1]))\n",
        "        if rejection_dist < distance:\n",
        "            tangentLine = centerLine\n",
        "            distance = rejection_dist\n",
        "\n",
        "    return distance, torch.atan2(tangentLine[1], tangentLine[0])\n",
        "\n",
        "\n",
        "# heading error computation\n",
        "def computeHeadingError(realHeading, desiredHeading):\n",
        "    delta = desiredHeading - torch.deg2rad(realHeading)\n",
        "    return torch.rad2deg(torch.atan2(torch.sin(delta), torch.cos(delta)))\n",
        "\n",
        "\n",
        "# constraints matrix scale values at the ouput of tanh [-1, 1]\n",
        "constraints = np.array([[0, 0, 0, 0],\n",
        "                        [0, 0, 0, 0],\n",
        "                        [0, 0, 5, 0],\n",
        "                        [0, 0, 0, 30]])\n",
        "\n",
        "\n",
        "class PathLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, skip_polyline_pts):\n",
        "        super(PathLoss, self).__init__()\n",
        "        self.lineDiscretization = skip_polyline_pts\n",
        "\n",
        "\n",
        "    def forward(self, position, direction, desiredVelocity, roadMap, verbose=False):\n",
        "        # unwrap road map information\n",
        "        leftBoundary, centerLine, rightBoundary = roadMap\n",
        "\n",
        "        # boundaryErrorLeft, boundaryErrorRight = 0, 0\n",
        "        # headingError = 0\n",
        "\n",
        "        # compute distance from road boundaries (want to maximize this)\n",
        "        boundaryErrorLeft, _ = shortestDistanceToPolyline(position, leftBoundary, self.lineDiscretization)\n",
        "        boundaryErrorRight, _ = shortestDistanceToPolyline(position, rightBoundary, self.lineDiscretization)\n",
        "\n",
        "        # compute distance from centerline (want to minimize this)\n",
        "        lateralError, roadHeading = shortestDistanceToPolyline(position, centerLine, self.lineDiscretization)\n",
        "\n",
        "        velocity, heading = direction\n",
        "        # compute heading & velocity errors\n",
        "        headingError = computeHeadingError(heading, roadHeading)\n",
        "        velocityError = desiredVelocity - velocity\n",
        "\n",
        "        # # turn max into min for distance from boundary lines\n",
        "        boundaryErrorLeft = torch.exp(5 * (1 - .2 * boundaryErrorLeft))\n",
        "        boundaryErrorRight = torch.exp(5 * (1 - .2 * boundaryErrorRight))\n",
        "\n",
        "        return boundaryErrorLeft, boundaryErrorRight, lateralError, velocityError, headingError\n",
        "        \n",
        "\n",
        "# compute obstacle avoidance loss\n",
        "class AvoidanceLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AvoidanceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, position, objects):\n",
        "\n",
        "        x, y = position\n",
        "\n",
        "        avoidance_loss = 0\n",
        "        for obj in objects:\n",
        "            obj_x, obj_y = obj\n",
        "            # ignore object if it is placeholder value\n",
        "            if obj_x != 0.0 or obj_y != 0.0:\n",
        "                distance = torch.sqrt(torch.square(x - obj_x) + torch.square(y - obj_y)) \n",
        "                avoidance_loss += torch.exp(2 * (4 - 0.5 * distance))\n",
        "                # avoidance_loss += torch.exp(2 - distance)\n",
        "\n",
        "        return avoidance_loss\n",
        "\n",
        "\n",
        "class PlannerLoss(nn.Module):\n",
        "\n",
        "    constraints = torch.tensor(constraints, dtype=torch.double)\n",
        "    \n",
        "    def __init__(self,\n",
        "                 costWeights,\n",
        "                 timeStep=1,\n",
        "                 lineDiscretization=3,\n",
        "                 gpu=False):\n",
        "        super(PlannerLoss, self).__init__()\n",
        "\n",
        "        self.avoid_loss_fn = AvoidanceLoss()\n",
        "        self.path_loss_fn = PathLoss(lineDiscretization)\n",
        "\n",
        "        self.gpu = gpu\n",
        "        if gpu:\n",
        "            self.constraints = self.constraints.cuda()\n",
        "        \n",
        "        self.timeStep = timeStep\n",
        "\n",
        "        self.laneWeight = costWeights[4]\n",
        "        self.avoidWeight = costWeights[3]\n",
        "        self.headingWeight = costWeights[2]\n",
        "        self.velocityWeight = costWeights[1]\n",
        "        self.centerLineWeight = costWeights[0]\n",
        "\n",
        "\n",
        "    def forward(self, initialState, controls, roadMaps, environments, verbose=False):\n",
        "        totalBatchCost = 0\n",
        "        batchDim = initialState.size(0)\n",
        "        \n",
        "        for i in range(batchDim):\n",
        "            cost = 0\n",
        "            # unwrap state, reduce last value in since it is desired velocity\n",
        "            state = initialState[i,:-1,...]\n",
        "            # unwrap desired velocity\n",
        "            desiredVelocity = initialState[i,-1,0]\n",
        "            # grab roadMap polyline points\n",
        "            roadMap = roadMaps[i,...]\n",
        "            # grab objects information\n",
        "            objects = environments[i,...]\n",
        "            for j in range(controls.size(1)):\n",
        "                cost_j = 0\n",
        "\n",
        "                if verbose:\n",
        "                    x, y, velocity, heading = state\n",
        "                    print(f\"state {j+1}:\")\n",
        "                    # print(f\"desired velocity: {desiredVelocity}\")\n",
        "                    print(f\"x: {x[0]}, y: {y[0]}, velocity: {velocity[0]}, heading: {heading[0] % 360}\")\n",
        "\n",
        "                # pad controls to do easy matrix multiplication update newState = T * currState\n",
        "                # where T is the transition matrix \n",
        "                paddedControls = torch.cat((torch.zeros(2, 1), controls[i,j,...]))\n",
        "                state = stateUpdateEqn(state, torch.matmul(self.constraints, paddedControls), self.timeStep)\n",
        "\n",
        "                # squeeze out last dimension so we can use list slicing on tensors\n",
        "                stateSqueeze = torch.squeeze(state)\n",
        "                positional_states, directional_states = stateSqueeze[:2], stateSqueeze[2:]                    \n",
        "\n",
        "                # compute error associated with obstacle avoidance\n",
        "                avoidanceError = self.avoid_loss_fn(positional_states, objects)\n",
        "                \n",
        "                # compute all errors associated with path loss\n",
        "                concatErrors = self.path_loss_fn(positional_states, \n",
        "                                                 directional_states, \n",
        "                                                 desiredVelocity, \n",
        "                                                 roadMap,\n",
        "                                                 verbose=verbose)\n",
        "                boundaryErrorLeft, boundaryErrorRight, lateralError, velocityError, headingError = concatErrors\n",
        "\n",
        "                # scale the weights increasing by time\n",
        "                timeScalar = 1 # (j + 1)\n",
        "                centerLineWeight = self.centerLineWeight * timeScalar\n",
        "                headingWeight = self.headingWeight * timeScalar\n",
        "                velocityWeight = self.velocityWeight * timeScalar\n",
        "\n",
        "                # add all errors to cost function\n",
        "                cost_j += centerLineWeight * torch.square(lateralError)\n",
        "                cost_j += velocityWeight * torch.square(velocityError)\n",
        "                cost_j += headingWeight * torch.abs(headingError)\n",
        "                cost_j += self.laneWeight * boundaryErrorLeft\n",
        "                cost_j += self.laneWeight * boundaryErrorRight \n",
        "                cost_j += self.avoidWeight * avoidanceError\n",
        "\n",
        "                cost += cost_j\n",
        "\n",
        "                if verbose:\n",
        "                    print(\"Left boundary cost:\", self.laneWeight * boundaryErrorLeft)\n",
        "                    print(\"Right boundary cost:\", self.laneWeight * boundaryErrorRight)\n",
        "                    print(\"Center lane cost:\", centerLineWeight * torch.square(lateralError))\n",
        "                    print(\"Velocity cost:\", velocityWeight * torch.square(velocityError))\n",
        "                    print(\"Heading cost:\", headingWeight * torch.abs(headingError))\n",
        "                    print(\"Obstacle cost:\", self.avoidWeight * avoidanceError)\n",
        "                    print(f\"Cost for time step {j + 1}: {cost_j}\")\n",
        "                    \n",
        "            if verbose:\n",
        "                print(\"Total cost:\", cost)\n",
        "\n",
        "            totalBatchCost += cost\n",
        "\n",
        "        # return average of cost function across batch\n",
        "        return totalBatchCost / batchDim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFm8ysvtNTU7"
      },
      "source": [
        "TODO: Make hidden size of four to encode the state information\n",
        "\n",
        "For loss function, fix scalars. We want it to converge as soon as possible while giving it some distance to converge\n",
        "\n",
        "Maybe just put loss on last state??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n6d49ma6K2i"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "n_steps = 15 # number of output controls\n",
        "\n",
        "n_features = 3 # velocity, heading, terminal velocity\n",
        "n_layers = n_steps # number of layers in RNN\n",
        "\n",
        "output_features = 2 # acceleration, angular velocity\n",
        "hidden_dim = 300 # hidden dimension size\n",
        "\n",
        "road_downsample = 6 # embedding size of road is len(road) / road_downsample\n",
        "\n",
        "# choose which road map\n",
        "road_map = road5\n",
        "road_map_cl = road5_cl\n",
        "\n",
        "# get only left boundary, centerline, right boundary\n",
        "# expand dims to concatenate\n",
        "left_boundary = np.expand_dims(road_map[0], axis=0)\n",
        "center_lane = np.expand_dims(road_map_cl, axis=0)\n",
        "right_boundary = np.expand_dims(road_map[-1], axis=0)\n",
        "road_map_input = np.concatenate((left_boundary, center_lane, right_boundary))\n",
        "xlim, ylim = None, None\n",
        "\n",
        "# unsqueeze to add batch dimension \n",
        "road_map_input = torch.unsqueeze(torch.tensor(road_map_input), dim=0).double()\n",
        "\n",
        "timestep = 1\n",
        "desired_velocity = 1e-10 # m/s\n",
        "init_heading = 0\n",
        "init_velocity = 6\n",
        "\n",
        "n_neighbors = 30\n",
        "\n",
        "cost_fn_weights = [20, 11, 9, 100, 40] # centerLineWeight, velocityWeight, headingWeight, avoidanceWeight, boundaryWeight\n",
        "# cost_fn_weights = [15, 8, 5, 40, 15] # centerLineWeight, velocityWeight, headingWeight, avoidanceWeight, boundaryWeight\n",
        "\n",
        "model = PathPlanner(n_steps, hidden_dim, n_features, output_features, n_neighbors, n_layers, (road_map.shape[1], road_downsample))\n",
        "model = model.double()\n",
        "\n",
        "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of trainable params in model: {pytorch_total_params}\\n')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "loss_fn = PlannerLoss(cost_fn_weights, timeStep=timestep, lineDiscretization=road_downsample)\n",
        "x, environments = buildDataset(1, desired_velocity, init_velocity=init_velocity, init_heading=init_heading, n_objects=n_neighbors)\n",
        "\n",
        "# pad the two zeros (x, y) to initial states\n",
        "initial_states = np.concatenate((np.zeros((x.shape[0], 2, 1)), np.swapaxes(x, -1, -2)), axis=1)\n",
        "x = torch.tensor(x, dtype=torch.double)\n",
        "environments = torch.tensor(environments, dtype=torch.double)\n",
        "\n",
        "print(\"inital heading\", np.squeeze(initial_states)[-2] % 360, '\\n')\n",
        "\n",
        "initial_states = torch.tensor(initial_states, dtype=torch.double)\n",
        "\n",
        "epochs = 500\n",
        "display = 50\n",
        "\n",
        "best_loss, best_soln = float('inf'), None\n",
        "\n",
        "output_no = 0\n",
        "\n",
        "for epoch in range(epochs + 1):\n",
        "    model.train()\n",
        "\n",
        "    output_info = epoch % display == 0 and epoch != 0\n",
        "\n",
        "    controls_output = model(x, road_map_input, environments)\n",
        "    loss = loss_fn(initial_states, \n",
        "                   controls_output,\n",
        "                   road_map_input,\n",
        "                   environments,\n",
        "                   verbose=output_info)\n",
        "\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        best_soln = getUpdatedStates(initial_states.detach().numpy(), controls_output.detach().numpy(), timestep)\n",
        "\n",
        "    if output_info:\n",
        "        savefig = f'/content/drive/My Drive/Research/Chance-Constraints/Traj-Outputs/{output_no}.png'\n",
        "        print_states = getUpdatedStates(initial_states.detach().numpy(), controls_output.detach().numpy(), timestep)\n",
        "        plot_trajectory(print_states, road_map, road_map_cl, environments.detach().numpy()[0], savefig=savefig, xlim=xlim, ylim=ylim, verbose=0)\n",
        "        min_dist = validate_avoidance(print_states, environments.detach().numpy()[0])\n",
        "        print(f'\\nloss = {loss}')\n",
        "        print(f'Minimum distance from objects: {min_dist}\\n\\n')\n",
        "        output_no += 1\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train full model below"
      ],
      "metadata": {
        "id": "T49_L89Bhqwa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTDM7XzIrv0W"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader\n",
        "\n",
        "# batch_size = 10 \n",
        "# n_workers = 1\n",
        "\n",
        "# n_steps = 8\n",
        "\n",
        "# train_dataset = ControlsDataset(buildDataset(100000, n_steps))\n",
        "# val_dataset = ControlsDataset(buildDataset(20000, n_steps))\n",
        "# # train_dataset = ControlsDataset(buildDataset(5, n_steps))\n",
        "# # val_dataset = ControlsDataset(buildDataset(2, n_steps))\n",
        "# validation_set = DataLoader(val_dataset,\n",
        "#                             batch_size=batch_size,\n",
        "#                             shuffle=True,\n",
        "#                             num_workers=n_workers,\n",
        "#                            )\n",
        "# training_set = DataLoader(train_dataset,\n",
        "#                           batch_size=batch_size,\n",
        "#                           shuffle=True,\n",
        "#                           num_workers=n_workers,\n",
        "#                          )\n",
        "# dataset = { 'validation': validation_set, 'train': training_set }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMlVOA5x1MVF"
      },
      "outputs": [],
      "source": [
        "# n_features = 4\n",
        "# n_layers = 7\n",
        "\n",
        "# best_path = '/content/drive/My Drive/Research/cc_best.pth'\n",
        "# chkpt_path = '/content/drive/My Drive/Research/cc_chkpt.pth'\n",
        "\n",
        "# hidden_dim = n_features\n",
        "# output_size = n_features\n",
        "\n",
        "# learning_rate = 1e-2\n",
        "\n",
        "# log_batch = 1000\n",
        "\n",
        "# zero_heading = 270 # degrees()\n",
        "# runway_heading = 54.331\n",
        "# desired_states = (50, runway_heading + zero_heading) # m/s, degrees()\n",
        "# center_line = torch.tensor([2421, -1737], dtype=torch.double)\n",
        "# cost_fn_weights = [13, 2, 6] # centerLineWeight, velocityWeight, headingWeight\n",
        "\n",
        "# gpu_exists = torch.cuda.device_count() > 0\n",
        "# print(f'GPU: {int(gpu_exists)}')\n",
        "\n",
        "# model = RNN(n_features, hidden_dim, output_size, n_layers, gpu=gpu_exists)\n",
        "# model = model.double()\n",
        "# model.load_state_dict(torch.load(chkpt_path))\n",
        "\n",
        "# pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "# print(f'Number of trainable params in model: {pytorch_total_params}')\n",
        "\n",
        "# if gpu_exists:\n",
        "#     model = model.cuda()\n",
        "#     center_line = center_line.cuda()\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# loss_fn = PathLoss(desired_states, center_line, cost_fn_weights, gpu=gpu_exists)\n",
        "\n",
        "# best_loss = 1e20\n",
        "# epochs = 100\n",
        "# for epoch in range(epochs):\n",
        "#     for phase in ['train', 'validation']:\n",
        "#         cumu_loss = 0\n",
        "#         total_loss = 0\n",
        "#         break_line = '-' * 20\n",
        "#         print(f'{break_line}\\n{phase} at epoch no. {epoch + 1}\\n{break_line}')\n",
        "#         for i, sample in enumerate(dataset[phase]):\n",
        "#             x, initial_states = sample\n",
        "\n",
        "#             if gpu_exists:\n",
        "#                 x = x.cuda()\n",
        "#                 initial_states = initial_states.cuda()\n",
        "\n",
        "#             if phase == 'train':\n",
        "#                 model.train()\n",
        "#             else:\n",
        "#                 model.eval()\n",
        "\n",
        "#             controls_output = model(x)\n",
        "#             loss = loss_fn(initial_states, controls_output, verbose=0)\n",
        "\n",
        "#             cumu_loss += loss\n",
        "#             total_loss += loss\n",
        "#             if phase == 'train':\n",
        "#                 model.zero_grad()\n",
        "#                 loss.backward()\n",
        "#                 optimizer.step()\n",
        "\n",
        "#             if i != 0 and i % log_batch == 0:                \n",
        "#                 print(f'batch {i}: loss = {cumu_loss / log_batch}')\n",
        "#                 if gpu_exists:\n",
        "#                     save_model = model.module if torch.cuda.device_count() > 1 else model\n",
        "#                 else:\n",
        "#                     save_model = model\n",
        "#                 torch.save(save_model.state_dict(), chkpt_path)\n",
        "#                 cumu_loss = 0\n",
        "\n",
        "#         if phase == 'validation':\n",
        "#             if total_loss / len(dataset['validation']) < best_loss:\n",
        "#                 best_loss = total_loss / len(dataset['validation'])\n",
        "#                 print(f'Loss improved! ({best_loss}) Saving model...')\n",
        "#                 if gpu_exists:\n",
        "#                     save_model = model.module if torch.cuda.device_count() > 1 else model\n",
        "#                 else:\n",
        "#                     save_model = model\n",
        "#                 torch.save(save_model.state_dict(), best_path)\n",
        "\n",
        "#         if gpu_exists:\n",
        "#             save_model = model.module if torch.cuda.device_count() > 1 else model\n",
        "#         else:\n",
        "#             save_model = model\n",
        "#         torch.save(save_model.state_dict(), chkpt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc80bVZSVTl0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "self_driving_model_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}